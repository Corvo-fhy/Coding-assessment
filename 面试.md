# OPPO面试 一面

## adam优化器原理
adam优化器是深度学习的一个优化方法，它结合了动量以及自适应学习率的概念，可以提高梯度下降算法的效率和收敛速度。

Adam算法维护了两个动量变量，分别是一阶矩（均值），和二阶矩（未中心化的方差）。给定一个目标函数的梯度$g_t$，则Adam算法的更新步骤可以表示为：

1.  计算一阶矩：$m_t = m_{t-1} * \beta_1 + g_t * (1-\beta_1)$ 
2.  计算二阶矩：$v_t = v_{t-1} * \beta_2 + g_t^2 * (1-\beta_2)$
3.  矫正一阶矩和二阶矩：$\hat{m_{t}} = m_t / (1-\beta_1^t)$ $\hat{v_{t}} = v_t / (1-\beta_2^t)$ 
4.  更新参数：$\theta(t) = \theta(t-1) - \alpha * \hat{m_t} / (sqrt(\hat{v_t}) + \epsilon)$， 其中\epsilon为防止除0的很小的数，\alpha为学习率。

Adam算法通过同时考虑梯度的一阶矩估计和二阶矩估计，可以自适应地调整学习率，适应不同参数的梯度变化情况。一阶矩估计相当于动量法，用于平滑梯度的变化；二阶矩估计相当于RMSProp算法，用于自适应地调整学习率的大小。

Adam算法的优势在于对于大多数问题，具有很好的效果。它具有快速收敛速度、适应性学习率和稳定的性能。

## 连续特征转为离散的好处
1.  增加鲁棒性：如年龄，将样本分为少年，青年和老年，可以有效防止异常值，如将年龄300直接分为老年。
2.  简化模型，减少过拟合风险：原有连续特征取值的可能性很多，离散化后该特征的取值可能性大幅减少，简化了模型，降低了过拟合的风险。
3.  减少计算量：简单的离散值计算内积比连续值快。
4.  提高模型的解释性：对于某些应用场景来说，离散化的特征比一个连续值可以让模型的结果更容易被理解和解释。
5.  方便特征交互：离散化后的特征更适合与其他特征进行交互操作（如构建特征组合）。离散特征通常有有限的取值，这使得交互后的特征维度可控，且组合后的特征容易被模型理解和利用。
## 正则化
正则化（Regularization）是机器学习中一种常用的技术，其主要目的是控制模型复杂度，减小过拟合。最基本的正则化方法是在原目标（代价）函数 中添加惩罚项，对复杂度高的模型进行“惩罚”。用于惩罚参数过大，促使模型更加稀疏化。
1.  L1正则化方法：L1正则化是指参数向量$W$中各个元素的绝对值之和:
    $$
    \sum_i=|W_i|
    $$
    用于惩罚参数过大，使模型更加稀疏。L1正则化使得绝大部分的参数都为0，从而达到特征选择(feature selection)的效果，在一些需要特征选择的问题上表现得更加优秀。但L1正则化的导数在0时不可导，使得优化问题更加复杂。
2.  L2正则化方法：L2正则化指参数向量$W$中各个元素的平方和：
    $$
    \sum_i=W_i^2
    $$
    用于惩罚参数过大，使模型更加平滑。L2正则化保留了更多的参数，使其更加连续和稳定，此外，L2正则化的导数在所有位置都可导，优化问题比L1正则化要简单，更加常用。
## DIN的注意力机制
1.  DIN是一个CTR模型，它可以建模不同长度的行为序列，同时可以计算用户历史行为内不同交互物品对候选广告的重要程度，它通过一个注意力机制实现行为序列embedding的加权和（Weighted Sum Pooling），文章采用一个神经网络（Activation Unit）来得到Weight：
    
        该神经网络的输入为两个部分,一个是原始的用户行为embedding，另一个是候选广告embedding，首先将这两个embedding进行out product操作（可以是向量加、减、点乘），将交互结果与原始的两个embedding拼接，输入到一个MLP中，最终通过一个全连接层得到这个拼接向量的权重，也就是这个用户历史行为的注意力得分。

## 项目细节
## 特征工程
数据探索和预处理：连续值变离散，特征分桶。缺失值处理。

## 粗排模型：YouTubeDNN、DSSM


# 蚂蚁 一面
这个部门是检索部门

## 介绍DIN，DIN对于行为序列如何做的

## XGBoost简介，他与bagging的不同

## 检索方向有了解吗
RAG，检索增强生成，相当于给LLM外挂一个知识库，包括检索召回部件以及大模型部件。

## 大模型有了解吗
SFT，DPO，

## 代码题:最大子数组和（没做出来）


# 蚂蚁 二面

## 介绍项目

## resnet如何缓解梯度消失

## 蒙特卡洛方法

## 强化学习，reward， return， state_value分别是什么

## 项目可能比较中规中矩，可能需要其他的一些东西加分

## 面试官能看到笔试成绩，笔试需要认真做

# 快手 一面
垂类推荐 

## 感觉像kpi面，啥也没问

## 二分法找循环数组的key

# 快手 二面

## 讲了半个小时项目，面试官建议可以打磨下细节（热门用户与非热门用户都归一化有什么问题？）

## 智力题：一根粉笔，摔倒地上三部分，这三部分组成三角形的概率是多少
没做出来。。。![alt text](/img/image.png)


# 美团第二次 一面
又是搜索部门

## 缺少经验，了解大模型在推荐、搜索业界相关的一些内容

## 了解大模型的内部原理

## 代码题：删除倒数第K个链表



# 淘天
搜推智能产品事业部-商品推荐算法
这个面试官挺nice的，一直引导我，最后还问了有没有要展示的(伏笔，挂了)

## 介绍项目

## 大模型相关内容（transformer，Bert，decoder-only大模型的结构）

## 你做的是多行为，那工业界多任务你了解吗

## 代码题：反转链表，k个一组反转链表

# 饿了么
首页推荐

## 介绍项目
得到用户物品的embedding之后还能怎么做

## 介绍DIN，Transformer，MMoE，
DIN中attention具体如何做，为什么用out product
为什么transformer对于长序列建模优于RNN，LSTM，transformer的位置编码怎么做的，为什么用三角函数
MMoE专家极化现象是什么，如何解决

## 给你多个特征，如何从中选出最重要的几个（如现在来了10个特征，我现在只保留3个，保留哪三个）

## 评价指标AUC，GAUC如何定义，他们的区别，HR的定义

## 讲一下推荐系统的流程（召回-排序一类）

## 代码题：编辑距离

# 夸克
夸克浏览器搜索

## 介绍项目

## 大模型了解吗（微调怎么做，对齐怎么做）

## 介绍对比学习，以及对比学习的一些loss函数

## 介绍LoRA，介绍强化学习

## KL散度和交叉熵的关系

## 代码题：最长回文字串

## 智力题：
有编号1~100的等，目前全开着，按照以下规则：
将编号为1的倍数灯的开关反向拨动一次，
将编号为2的倍数灯的开关反向拨动一次，
......，
将编号为100的倍数灯的开关反向拨动一次
问最后哪些灯是关着的

# 腾讯
腾讯视频

## 介绍项目

## 介绍DIN，MMOE

## 介绍transformer，attention公式
transformer的attention与DIN的attention有何不同，attention为什么除以根号下$d_k$

## 双塔模型，以及它的改进

## 代码题：旋转数组的查找

# 华为
终端云服务

## 介绍项目
得到user与item的embedding之后还可以怎么做

## DIN，Transformer
这两个的attention是如何做的，有什么不同，介绍transformer

## ESMM->MMOE->PLE
他们的创新点，解决的问题，以及相对上一个改进的问题，PLE可以堆叠多层，你认为这样的优点

## 代码题：生成括号

# 夸克
二面

## 介绍项目
只用了LLM zero-short的能力，可以再进行一些深入的研究，比如大模型微调

## 你了解DeepSeek厉害的原因吗
这个真不知道

## ESMM->MMOE->PLE

## 智力题
54张扑克牌，分为3堆，问大小王在同一堆的概率

一个人在地球上，他向南走1km，向东走1km，向北走1km，最终回到了原位，问这个人在地球上哪些点

8个小球，7个正常，1个轻，问最少称几次能找出轻的